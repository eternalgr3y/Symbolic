diff --git a/agent.py b/agent.py
--- a/agent.py
+++ b/agent.py
@@ -1,11 +1,12 @@
 # symbolic_agi/agent.py

 import asyncio
 import json
 import logging
-from typing import TYPE_CHECKING, Any, Callable, Dict
+from typing import TYPE_CHECKING, Any, Dict

 from openai import AsyncOpenAI
+from skill_manager import register_innate_action

 from . import prompts
 from .api_client import monitored_chat_completion
@@ -19,33 +20,13 @@
         self.persona = name.split("_")[-2].lower() if "_" in name else "specialist"
         self.bus = message_bus
         self.client = api_client
-        self.inbox = self.bus.subscribe(self.name)
+        self.inbox: asyncio.Queue[MessageModel] = self.bus.subscribe(self.name)
         self.running = True
-        self.skills: Dict[str, Callable[..., Any]] = self._initialize_skills()
         logging.info(
-            "Agent '%s' initialized with persona '%s' and skills: %s",
+            "Agent '%s' initialized with persona '%s'",
             self.name,
             self.persona,
-            list(self.skills.keys()),
-        )
-
-    def _initialize_skills(self) -> Dict[str, Callable[..., Any]]:
-        """Initializes persona-specific skills."""
-        if self.persona == "coder":
-            return {"write_code": self.skill_write_code}
-        if self.persona == "research":
-            return {"research_topic": self.skill_research_topic}
-        if self.persona == "qa":
-            return {
-                "review_code": self.skill_review_code,
-                "review_plan": self.skill_review_plan,
-                "review_skill_efficiency": self.skill_review_skill_efficiency,
-            }
-        if self.persona == "browser":
-            return {"interact_with_page": self.skill_interact_with_page}
-        return {}
-        skill_to_run = self.skills.get(message.message_type)
-        if skill_to_run:
-            result_payload = await skill_to_run(message.payload)
-            await self._reply(message, result_payload)
+
+        # Find the skill method decorated for this agent's persona and message type
+        skill_method = None
+        if hasattr(self, message.message_type):
+            method = getattr(self, message.message_type)
+            if hasattr(method, "_innate_action_persona"):
+                if method._innate_action_persona == self.persona:
+                    skill_method = method
+
+        if skill_method:
+            result_payload = await skill_method(message.payload)
+            await self._reply(message, result_payload)
         elif message.message_type == "new_skill_broadcast":
             skill_name = message.payload.get("skill_name")
             skill_description = message.payload.get("skill_description")
@@ -108,6 +96,9 @@
                 },
             )

+    @register_innate_action(
+        "browser", "Analyzes a web page and decides the next interaction."
+    )
     async def skill_interact_with_page(self, params: Dict[str, Any]) -> Dict[str, Any]:
         """
         Analyzes the content of a web page and decides the next interaction.
@@ -134,6 +125,10 @@
         except Exception as e:
             return {"status": "failure", "error": str(e)}

+    @register_innate_action(
+        "qa",
+        "Reviews a learned skill's action sequence for potential improvements.",
+    )
     async def skill_review_skill_efficiency(
         self, params: Dict[str, Any]
     ) -> Dict[str, Any]:
@@ -173,6 +168,9 @@
             )
             return {"status": "failure", "error": str(e)}

+    @register_innate_action(
+        "qa", "Reviews a plan for logical flaws or inefficiency."
+    )
     async def skill_review_plan(self, params: Dict[str, Any]) -> Dict[str, Any]:
         """
         Reviews a plan for logical flaws, inefficiency, or misinterpretation of the
@@ -202,6 +200,9 @@
         except Exception as e:
             return {"status": "failure", "error": str(e)}

+    @register_innate_action(
+        "coder", "Generates Python code based on a prompt and context."
+    )
     async def skill_write_code(self, params: Dict[str, Any]) -> Dict[str, Any]:
         """Generates Python code, using and updating its own short-term state."""
         prompt = params.get("prompt", "Write a simple hello world python script.")
@@ -235,6 +236,9 @@
         except Exception as e:
             return {"status": "failure", "error": str(e)}

+    @register_innate_action(
+        "research", "Researches a given topic and provides a concise summary."
+    )
     async def skill_research_topic(self, params: Dict[str, Any]) -> Dict[str, Any]:
         """Researches a given topic and provides a concise summary."""
         topic = params.get("topic", "The history of artificial intelligence.")
@@ -251,6 +255,9 @@
         except Exception as e:
             return {"status": "failure", "error": str(e)}

+    @register_innate_action(
+        "qa", "Reviews provided Python code for quality and improvements."
+    )
     async def skill_review_code(self, params: Dict[str, Any]) -> Dict[str, Any]:
         """Reviews provided Python code for quality and improvements."""
         workspace = params.get("workspace", {})
--- a/agi_controller.py
+++ b/agi_controller.py
@@ -99,7 +99,7 @@

     async def start_background_tasks(self) -> None:
         playwright = await async_playwright().start()
-        self.browser = await playwright.chromium.launch(headless=False)
+        self.browser = await playwright.chromium.launch(headless=True)
         logging.info("Playwright browser instance started.")

         await self.meta_cognition.run_background_tasks()
@@ -155,24 +155,25 @@
         This is an event-driven approach, superior to polling.
         """
         logging.info("Async workspace watchdog started.")
-        try:
-            async for changes in awatch(self.tools.workspace_dir):
+        workspace_path = os.path.abspath(self.tools.workspace_dir)
+        try:
+            async for changes in awatch(workspace_path):
                 for change_type, path in changes:
-                    file_path = os.path.relpath(path, self.tools.workspace_dir)
+                    file_path = os.path.relpath(path, workspace_path)
                     logging.info(
                         "PERCEPTION: Detected file change '%s' in workspace: %s",
                         change_type.name,
                         file_path,
                     )
                     event = PerceptionEvent(
-                        type="agent_appeared",
+                        type="file_modified",
                         source="workspace",
-                        content={"message": "User input received"},
+                        content={"change": change_type.name, "path": file_path},
                         timestamp=datetime.now(timezone.utc).isoformat(),
                     )
                     self.perception_buffer.append(event)
         except asyncio.CancelledError:
-            logging.info("Async workspace watchdog cancelled.")
+            logging.info("Async workspace watchdog has been cancelled.")
         except Exception as e:
             logging.error("Error in workspace watchdog task: %s", e, exc_info=True)

--- a/consciousness.py
+++ b/consciousness.py
@@ -1,5 +1,6 @@
 # symbolic_agi/consciousness.py
 import json
+import atexit
 import logging
 import os
 from collections import deque
@@ -37,6 +38,7 @@
             }
             self._is_dirty = True
             self._save_profile()
+        atexit.register(self._save_profile)

     def _load_profile(self: "Consciousness") -> Dict[str, Any]:
         """Loads the persistent identity profile from a JSON file."""
@@ -62,6 +64,7 @@
         os.makedirs(os.path.dirname(self.file_path), exist_ok=True)
         with open(self.file_path, "w", encoding="utf-8") as f:
             json.dump(self.profile, f, indent=4)
+        logging.info("Consciousness profile saved to %s", self.file_path)
         self._is_dirty = False

     def set_drive(self: "Consciousness", drive_name: str, value: float) -> None:
@@ -72,7 +75,6 @@
         if drive_name in self.drives:
             self.drives[drive_name] = max(0.0, min(1.0, value))
             self._is_dirty = True
-            # Defer saving to shutdown hook
         else:
             logging.warning("Attempted to set unknown drive: %s", drive_name)

@@ -83,7 +85,6 @@
         event = LifeEvent(summary=event_summary, importance=importance)
         self.life_story.append(event)
         self._is_dirty = True
-        # Defer saving to shutdown hook

     def get_narrative(self: "Consciousness") -> str:
         """Constructs a narrative string from the most recent and important life events."""
--- a/long_term_memory.py
+++ b/long_term_memory.py
@@ -1,5 +1,6 @@
 # symbolic_agi/long_term_memory.py

+import atexit
 import json
 import logging
 import os
@@ -17,13 +18,11 @@
         self._is_dirty = False
         self.goals: Dict[str, GoalModel] = self._load_goals()
         logging.info("[LTM] Initialized with %d goals.", len(self.goals))
+        atexit.register(self.save)

     def _load_goals(self) -> Dict[str, GoalModel]:
         """Loads active goals from a JSON file, validating them with Pydantic."""
-        if (
-            not os.path.exists(config.LONG_TERM_GOAL_PATH)
-            or os.path.getsize(config.LONG_TERM_GOAL_PATH) < 2
-        ):
+        if not os.path.exists(self.file_path) or os.path.getsize(self.file_path) < 2:
             return {}
         try:
             with open(self.file_path, "r", encoding="utf-8") as f:
@@ -49,12 +48,12 @@
                 },
                 f,
                 indent=4,
             )
+        logging.info("Long-term memory saved to %s", self.file_path)
         self._is_dirty = False

     def add_goal(self, goal: GoalModel) -> None:
         """Adds a new goal to the long-term memory."""
         self.goals[goal.id] = goal
         self._is_dirty = True
-        self.save()

     def get_goal_by_id(self, goal_id: str) -> Optional[GoalModel]:
         """Retrieves a goal by its unique ID."""
@@ -65,7 +64,6 @@
         if goal := self.goals.get(goal_id):
             goal.status = status  # type: ignore[assignment]
             self._is_dirty = True
-            self.save()

     def get_active_goal(self) -> Optional[GoalModel]:
         """Retrieves the first active goal from the list."""
@@ -79,7 +77,6 @@
             if goal.sub_tasks:
                 goal.sub_tasks.pop(0)
                 self._is_dirty = True
-                self.save()

     def update_plan(self, goal_id: str, plan: List[ActionStep]) -> None:
         """Updates the entire plan for a goal and sets the original plan if not set."""
@@ -88,7 +85,6 @@
             if goal.original_plan is None:
                 goal.original_plan = plan
             self._is_dirty = True
-            self.save()

     def invalidate_plan(self, goal_id: str, reason: str) -> None:
         """Marks a plan as invalid by clearing it and recording the failure reason."""
@@ -96,21 +92,18 @@
             goal.sub_tasks = []
             goal.last_failure = reason
             self._is_dirty = True
-            self.save()

     def increment_failure_count(self, goal_id: str) -> int:
         """Increments the failure count for a goal and returns the new count."""
         if goal := self.goals.get(goal_id):
             goal.failure_count += 1
             self._is_dirty = True
-            self.save()
             return goal.failure_count
         return 0

     def increment_refinement_count(self, goal_id: str) -> int:
         """Increments the refinement count for a goal and returns the new count."""
         if goal := self.goals.get(goal_id):
             goal.refinement_count += 1
             self._is_dirty = True
-            self.save()
             return goal.refinement_count
         return 0

@@ -132,7 +125,6 @@
                 with open(config.GOAL_ARCHIVE_PATH, "w", encoding="utf-8") as f:
                     json.dump(archive_data, f, indent=4)
                 self._is_dirty = True
-                self.save()  # Save the main goals file after removal
             except Exception as e:
                 logging.error(
                     "Failed to archive goal %s: %s", goal.id, e, exc_info=True
--- a/planner.py
+++ b/planner.py
@@ -2,6 +2,7 @@

 import json
 import logging
+from pydantic import TypeAdapter, ValidationError
 from typing import Any, Dict, List, Optional, cast

 from .agent_pool import DynamicAgentPool
@@ -233,14 +234,13 @@
                 )

         try:
-            validated_plan = [
-                ActionStep.model_validate(item) for item in repaired_plan_steps
-            ]
-        except Exception as e:
+            ActionStepList = TypeAdapter(List[ActionStep])
+            validated_plan = ActionStepList.validate_python(repaired_plan_steps)
+        except ValidationError as e:
             logging.error(
                 "Failed to validate repaired plan structure: %s", e, exc_info=True
             )
             return PlannerOutput(
                 thought=f"Failed to validate plan structure: {e}", plan=[]
             )
--- a/run_agi.py
+++ b/run_agi.py
@@ -1,15 +1,16 @@
 # symbolic_agi/run_agi.py

 import asyncio
-import atexit
 import logging
 import logging.handlers
 import signal
-from typing import Optional
+from typing import Any, Dict, Optional

 import colorlog
+import uvicorn
+from fastapi import FastAPI, HTTPException, Request
 from prometheus_client import start_http_server

 from . import metrics
 from .agent import Agent
 from .agi_controller import SymbolicAGI
 from .api_client import client
 from .schemas import AGIConfig, GoalMode, GoalModel

 SHUTDOWN_EVENT = asyncio.Event()


 def setup_logging(log_level: str = "INFO") -> None:
     """Sets up logging configuration."""
     log_file = "agi.log"
     max_bytes = 10 * 1024 * 1024
     backup_count = 5

     root_logger = logging.getLogger()
     root_logger.setLevel(logging.INFO)
     if root_logger.hasHandlers():
         root_logger.handlers.clear()

     file_handler = logging.handlers.RotatingFileHandler(
         log_file,
         mode="a",
         maxBytes=max_bytes,
         backupCount=backup_count,
         encoding="utf-8",
     )
     detailed_formatter = logging.Formatter(
         "%(asctime)s - [%(levelname)s] - (%(filename)s:%(lineno)d) - %(message)s"
     )
     file_handler.setFormatter(detailed_formatter)
     root_logger.addHandler(file_handler)

     console_handler = colorlog.StreamHandler()
     color_formatter = colorlog.ColoredFormatter(
         "%(log_color)s[%(levelname)s]%(reset)s - %(message)s",
         log_colors={
             "DEBUG": "cyan",
             "INFO": "green",
             "WARNING": "yellow",
             "ERROR": "red",
             "CRITICAL": "bold_red",
         },
     )
     console_handler.setFormatter(color_formatter)
     root_logger.addHandler(console_handler)


 async def main() -> None:  # noqa: C901
     """Initializes the AGI and runs the main interactive/autonomous loop."""
     agi: Optional[SymbolicAGI] = None

     async def autonomous_loop(agi_instance: SymbolicAGI) -> None:
         """The main cognitive heartbeat of the AGI."""
         while not SHUTDOWN_EVENT.is_set():
             try:
                 metrics.ACTIVE_GOALS.set(len(agi_instance.ltm.goals))
                 metrics.AGENT_TASKS_RUNNING.set(len(agi_instance.agent_tasks))
                 metrics.MEMORY_ENTRIES.set(
                     agi_instance.memory.get_total_memory_count()
                 )
                 if agi_instance.memory.faiss_index:
                     metrics.FAISS_INDEX_VECTORS.set(
                         agi_instance.memory.faiss_index.ntotal
                     )

                 if active_goal := agi_instance.ltm.get_active_goal():
                     logging.info(
                         "[Cycle] Working on goal: '%s'...", active_goal.description
                     )

                     result = (
                         await agi_instance.execution_unit.handle_autonomous_cycle()
                     )

                     status_message = result.get("description", "Cycle finished.")
                     logging.info("[Cycle] Status: %s", status_message)

                     if response_text := result.get("response_text"):
                         print(f"\nAGI: {response_text}\n")

                 await asyncio.sleep(5)
             except asyncio.CancelledError:
                 logging.info("Autonomous loop cancelled.")
                 break
             except Exception as e:
                 logging.critical(
                     "CRITICAL ERROR in autonomous loop: %s", e, exc_info=True
                 )
                 await asyncio.sleep(15)

-    async def user_input_loop(agi_instance: SymbolicAGI) -> None:
-        """Handles user input to create new goals."""
-        loop = asyncio.get_event_loop()
-        while not SHUTDOWN_EVENT.is_set():
-            try:
-                user_input = await loop.run_in_executor(
-                    None,
-                    lambda: input("Enter a new goal (or press Ctrl+C to exit):\n> "),
-                )
-                if user_input.strip():
-                    goal_mode: GoalMode = (
-                        "docs" if "document" in user_input.lower() else "code"
-                    )
-                    new_goal = GoalModel(
-                        description=user_input.strip(), sub_tasks=[], mode=goal_mode
-                    )
-                    agi_instance.ltm.add_goal(new_goal)
-                    logging.info(
-                        "Goal '%s' has been added to the queue (Mode: %s).",
-                        new_goal.description,
-                        goal_mode,
-                    )
-            except (EOFError, asyncio.CancelledError):
-                break
-
-    def shutdown_handler(signum: Optional[int] = None, frame: Optional[object] = None) -> None:
+    def shutdown_handler(
+        signum: Optional[int] = None, frame: Optional[object] = None
+    ) -> None:
         """Initiates a graceful shutdown."""
         if SHUTDOWN_EVENT.is_set():
             return
         logging.critical("Shutdown signal received. Initiating graceful shutdown...")
         SHUTDOWN_EVENT.set()

-    # Register shutdown handlers
-    atexit.register(shutdown_handler)
+    # Register signal handlers
     signal.signal(signal.SIGINT, shutdown_handler)
     signal.signal(signal.SIGTERM, shutdown_handler)

     try:
         setup_logging()
         logging.info("=" * 50)
         logging.info("--- INITIALIZING SYMBOLIC AGI SYSTEM (PERSISTENT MODE) ---")

-        start_http_server(8000)
-        logging.info("Prometheus metrics server started on port 8000.")
+        start_http_server(9090)
+        logging.info("Prometheus metrics server started on port 9090.")

         agi = SymbolicAGI()
         await agi.startup_validation()
@@ -137,16 +138,45 @@
             agi.agent_tasks.append(task)

         logging.info("--- %d SPECIALIST AGENTS ONLINE ---", len(agi.agent_tasks))
-        logging.info("--- AGI CORE ONLINE. NOW FULLY AUTONOMOUS & PERSISTENT. ---")
+
+        # Setup FastAPI Admin Interface
+        app = FastAPI(title="SymbolicAGI Control Plane")
+        app.state.agi = agi
+
+        @app.post("/goal", status_code=202)
+        async def create_goal(request: Request, body: Dict[str, Any]) -> Dict[str, str]:
+            """Accepts a new goal for the AGI."""
+            agi_instance: SymbolicAGI = request.app.state.agi
+            goal_description = body.get("description")
+            if not goal_description:
+                raise HTTPException(status_code=400, detail="`description` is required.")
+
+            goal_mode: GoalMode = "docs" if "document" in goal_description.lower() else "code"
+            new_goal = GoalModel(
+                description=goal_description.strip(), sub_tasks=[], mode=goal_mode
+            )
+            agi_instance.ltm.add_goal(new_goal)
+            logging.info(
+                "New goal added via API: '%s' (Mode: %s).",
+                new_goal.description,
+                goal_mode,
+            )
+            return {"status": "accepted", "goal_id": new_goal.id}
+
+        uvicorn_config = uvicorn.Config(app, host="0.0.0.0", port=8000, log_level="warning")
+        server = uvicorn.Server(uvicorn_config)
+
+        logging.info("--- AGI CORE ONLINE. CONTROL PLANE LISTENING ON PORT 8000. ---")
         logging.info(
-            "You can enter a new goal at any time. If idle, the AGI may generate its own."
+            "Submit new goals via POST to http://localhost:8000/goal"
         )
         logging.info("=" * 50 + "\n")

         main_tasks = [
             asyncio.create_task(autonomous_loop(agi)),
-            asyncio.create_task(user_input_loop(agi)),
+            asyncio.create_task(server.serve()),
         ]
+
         await asyncio.gather(*main_tasks, return_exceptions=True)

     except (KeyboardInterrupt, asyncio.CancelledError):
@@ -155,9 +185,11 @@
         logging.critical("A critical error occurred in the main runner:", exc_info=True)
     finally:
         SHUTDOWN_EVENT.set()
+        logging.info("Shutting down AGI controller and agents...")
         if agi:
             await agi.shutdown()

+        # Final save for any components that use atexit
         logging.info("All agents have been shut down.")


--- a/schemas.py
+++ b/schemas.py
@@ -13,6 +13,10 @@
     memory_forgetting_threshold: float = 0.2
     debate_timeout_seconds: int = 90
     energy_regen_amount: int = 5
+    initial_trust_score: float = 0.5
+    max_trust_score: float = 1.0
+    trust_decay_rate: float = 0.1
+    trust_reward_rate: float = 0.05


 # --- INTER-AGENT COMMUNICATION ---
--- a/skill_manager.py
+++ b/skill_manager.py
@@ -1,7 +1,7 @@
 # symbolic_agi/skill_manager.py

 import json
-import logging
+import logging, inspect
 import os
 from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional

@@ -16,14 +16,14 @@

 def register_innate_action(
     persona: str, description: str
-) -> Callable[[Callable[..., Any]], Callable[..., Any]]:
+) -> Callable[[Callable[..., Any]], Callable[..., Any]]:  # type: ignore
     """A decorator to register a tool or skill as an innate action."""

-    def decorator(func: Callable[..., Any]) -> Callable[..., Any]:
-        import inspect
+    def decorator(func: Callable[..., Any]) -> Callable[..., Any]:  # type: ignore

         params = []
         sig = inspect.signature(func)
+        func_name = func.__name__.replace("_action_", "")
         for param in sig.parameters.values():
             if param.name not in ("self", "kwargs"):
                 params.append(
@@ -35,11 +35,13 @@
                 )

         action_def = ActionDefinition(
-            name=func.__name__,
+            name=func_name,
             description=description,
             parameters=params,
             assigned_persona=persona,
         )
+        setattr(func, "_innate_action_persona", persona)
+        setattr(func, "_innate_action_def", action_def)
         _innate_action_registry.append(action_def)
         return func

--- a/symbolic_identity.py
+++ b/symbolic_identity.py
@@ -1,5 +1,6 @@
 # symbolic_agi/symbolic_identity.py

+import atexit
 import json
 import logging
 import os
@@ -34,6 +35,7 @@
         self.last_interaction_timestamp: datetime = datetime.now(timezone.utc)

         self._is_dirty = False
+        atexit.register(self.save_profile)

     def _load_profile(self: "SymbolicIdentity") -> Dict[str, Any]:
         """Loads the persistent identity profile from a JSON file."""
@@ -50,7 +52,7 @@
         if not self._is_dirty:
             return

-        logging.info("Saving updated identity profile to disk...")
+        logging.info("Saving updated identity profile to %s", self.file_path)
         try:
             profile_data: Dict[str, Any] = {
                 "name": self.name,
--- a/tool_plugin.py
+++ b/tool_plugin.py
@@ -1,13 +1,13 @@
 # symbolic_agi/tool_plugin.py

 # Standard library imports
-import asyncio
 import inspect
 import io
 import json
 import logging
 import os
-from concurrent.futures import ProcessPoolExecutor
+import asyncio
+from multiprocessing import Process, Queue
 from contextlib import redirect_stdout
 from datetime import datetime, timezone
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, cast
@@ -29,22 +29,29 @@


 # This function must be at the top level to be pickleable by ProcessPoolExecutor
-def _execute_sandboxed_code(code: str, result_queue: "Queue[Dict[str, Any]]") -> None:
+def _execute_sandboxed_code(code: str, result_queue: Queue) -> None:  # type: ignore
     """Executes code in a sandboxed environment and puts the result in a queue."""
     output_buffer = io.StringIO()
     try:
         # A very restrictive sandbox
-        safe_globals: Dict[str, Any] = {"__builtins__": {}}
+        safe_globals: Dict[str, Any] = {
+            "__builtins__": {
+                "print": print,
+                "len": len,
+                "range": range,
+                "str": str,
+                "int": int,
+                "float": float,
+                "list": list,
+                "dict": dict,
+                "set": set,
+                "True": True,
+                "False": False,
+                "None": None,
+            }
+        }
         with redirect_stdout(output_buffer):
             exec(code, safe_globals, {})
         result = {"status": "success", "output": output_buffer.getvalue()}
     except Exception as e:
         result = {
             "status": "failure",
             "output": output_buffer.getvalue(),
             "error": str(e),
         }
     result_queue.put(result)


 class ToolPlugin:
     """A collection of real-world tools for the AGI."""

     def __init__(self, agi: "SymbolICAGI"):
         self.agi = agi
         self.workspace_dir = os.path.abspath(config.WORKSPACE_DIR)
         os.makedirs(self.workspace_dir, exist_ok=True)
-        self.process_pool = ProcessPoolExecutor()

     # --- Browser Tools ---
     @register_innate_action(
@@ -370,35 +377,41 @@
         if code is None:
             return {
                 "status": "failure",
                 "description": "execute_python_code was called without code.",
             }
         logging.warning("Executing sandboxed Python code:\n---\n%s\n---", code)

-        loop = asyncio.get_running_loop()
-        result_queue: "Queue[Dict[str, Any]]" = Queue()
-
-        try:
-            # Schedule the sandboxed execution in a separate process
-            future = loop.run_in_executor(
-                self.process_pool, _execute_sandboxed_code, code, result_queue
-            )
-            # Wait for the result with a timeout
-            await asyncio.wait_for(future, timeout=timeout_seconds)
-            result = result_queue.get()
-
-            if result["status"] == "success":
-                logging.info("Code execution successful. Output:\n%s", result["output"])
-            else:
-                logging.error("Code execution failed. Error: %s", result.get("error"))
-
-            return result
-
+        result_queue: Queue = Queue()  # type: ignore
+        process = Process(target=_execute_sandboxed_code, args=(code, result_queue))
+
+        try:
+            process.start()
+            # Use asyncio.to_thread to wait for the process without blocking the event loop
+            await asyncio.to_thread(process.join, timeout=timeout_seconds)
+
+            if process.is_alive():
+                process.terminate()  # Forcefully terminate if it's still running
+                process.join()  # Wait for termination to complete
+                logging.error(
+                    "Code execution timed out after %d seconds and was terminated.",
+                    timeout_seconds,
+                )
+                return {
+                    "status": "failure",
+                    "description": "Error: Code execution took too long and was terminated.",
+                }
+
+            if not result_queue.empty():
+                result = result_queue.get()
+                if result["status"] == "success":
+                    logging.info("Code execution successful. Output:\n%s", result["output"])
+                else:
+                    logging.error("Code execution failed. Error: %s", result.get("error"))
+                return result
+            else:
+                return {"status": "failure", "description": "Code execution process finished without providing a result."}
         except asyncio.TimeoutError:
-            logging.error("Code execution timed out after %d seconds.", timeout_seconds)
-            # It's difficult to forcefully kill the process in the pool,
-            # but the result from that process will be ignored.
             return {
                 "status": "failure",
                 "description": "Error: Code execution took too long and was terminated.",
             }
         except Exception as e:
             error_message = (
                 f"An error occurred during code execution management: {type(e).__name__}: {e}"
             )
             logging.error(error_message, exc_info=True)
             return {"status": "failure", "description": error_message}
+        finally:
+            if process.is_alive():
+                process.terminate()

     @register_innate_action(
         "orchestrator", "Reads the content of one of the AGI's own source code files."
--- /dev/null
+++ b/.github/workflows/lint.yml
@@ -0,0 +1,31 @@
+name: Lint and Check for Duplicates
+
+on:
+  push:
+    branches: [ main ]
+  pull_request:
+    branches: [ main ]
+
+jobs:
+  lint:
+    runs-on: ubuntu-latest
+    steps:
+    - uses: actions/checkout@v4
+
+    - name: Set up Python
+      uses: actions/setup-python@v5
+      with:
+        python-version: '3.11'
+
+    - name: Install dependencies
+      run: |
+        python -m pip install --upgrade pip
+        pip install ruff mypy
+
+    - name: Run Ruff Linter
+      run: ruff check .
+
+    - name: Run MyPy Type Checker
+      run: mypy . --strict
+
+    - name: Check for duplicate files
+      run: python scripts/find_duplicates.py
--- /dev/null
+++ b/scripts/find_duplicates.py
@@ -0,0 +1,48 @@
+#!/usr/bin/env python3
+# scripts/find_duplicates.py
+
+import hashlib
+import os
+import sys
+from collections import defaultdict
+from pathlib import Path
+
+
+def find_duplicate_files(root_dir: Path) -> dict[str, list[str]]:
+    """
+    Finds files with duplicate content within a directory.
+
+    Args:
+        root_dir: The root directory to search.
+
+    Returns:
+        A dictionary mapping content hashes to lists of file paths.
+    """
+    hashes = defaultdict(list)
+    for dirpath, _, filenames in os.walk(root_dir):
+        # Ignore virtual environments and cache directories
+        if ".venv" in dirpath or "__pycache__" in dirpath or ".git" in dirpath:
+            continue
+
+        for filename in filenames:
+            if filename.endswith(".py"):
+                file_path = Path(dirpath) / filename
+                with open(file_path, "rb") as f:
+                    file_hash = hashlib.sha256(f.read()).hexdigest()
+                hashes[file_hash].append(str(file_path.relative_to(root_dir)))
+
+    return {key: value for key, value in hashes.items() if len(value) > 1}
+
+
+if __name__ == "__main__":
+    project_root = Path(__file__).parent.parent.resolve()
+    print(f"Scanning for duplicate Python files in: {project_root}")
+
+    duplicates = find_duplicate_files(project_root)
+
+    if duplicates:
+        print("\nERROR: Found duplicate files!", file=sys.stderr)
+        for file_hash, files in duplicates.items():
+            print(f"  - Hash: {file_hash[:10]}... Files: {', '.join(files)}", file=sys.stderr)
+        sys.exit(1)
+    else:
+        print("\nSuccess: No duplicate Python files found.")
+        sys.exit(0)
--- /dev/null
+++ b/test_micro_world.py
@@ -0,0 +1,111 @@
+# symbolic_agi/test_micro_world.py
+
+import os
+import json
+import pytest
+from unittest.mock import patch
+
+from micro_world import MicroWorld
+from config import DATA_DIR
+
+
+@pytest.fixture
+def world() -> MicroWorld:
+    """Fixture to create a clean MicroWorld instance for each test."""
+    # Ensure we don't use a real state file for tests
+    with patch("micro_world.MicroWorld._load_state") as mock_load:
+        world_instance = MicroWorld()
+        # Provide a fresh, default state for each test
+        world_instance.state = world_instance._get_default_state()
+        mock_load.return_value = world_instance.state
+        return world_instance
+
+
+def test_world_initialization(world: MicroWorld) -> None:
+    """Test that the world initializes with default agents and objects."""
+    assert len(world.state["agents"]) == 4
+    assert len(world.state["objects"]) > 0
+    assert world.get_agent("SymbolicAGI") is not None
+    assert world.get_object("Chest") is not None
+
+
+@pytest.mark.asyncio
+async def test_action_move_success(world: MicroWorld) -> None:
+    """Test a successful move action."""
+    agent_name = "SymbolicAGI"
+    initial_location = world.get_agent(agent_name)["location"]
+    assert initial_location == "hallway"
+
+    result = await world.perform_action("move", agent_name=agent_name, new_location="room1")
+
+    assert result["status"] == "success"
+    assert world.get_agent(agent_name)["location"] == "room1"
+
+
+@pytest.mark.asyncio
+async def test_action_move_fail_no_exit(world: MicroWorld) -> None:
+    """Test a move action that fails due to no direct exit."""
+    agent_name = "SymbolicAGI"
+    world.get_agent(agent_name)["location"] = "room1"
+
+    result = await world.perform_action("move", agent_name=agent_name, new_location="room2")
+
+    assert result["status"] == "failure"
+    assert "No direct exit" in result["description"]
+    assert world.get_agent(agent_name)["location"] == "room1"
+
+
+@pytest.mark.asyncio
+async def test_action_pickup_and_drop(world: MicroWorld) -> None:
+    """Test picking up and dropping an object."""
+    agent_name = "SymbolicAGI"
+    object_name = "Stick"
+
+    # Move agent to the room with the stick
+    await world.perform_action("move", agent_name=agent_name, new_location="room1")
+    agent = world.get_agent(agent_name)
+    obj = world.get_object(object_name)
+
+    assert object_name not in agent["inventory"]
+    assert obj["location"] == "room1"
+
+    # Pick up the stick
+    pickup_result = await world.perform_action("pickup", agent_name=agent_name, object_name=object_name)
+    assert pickup_result["status"] == "success"
+    assert object_name in agent["inventory"]
+    assert obj["location"] == "inventory"
+
+    # Drop the stick
+    drop_result = await world.perform_action("drop", agent_name=agent_name, object_name=object_name)
+    assert drop_result["status"] == "success"
+    assert object_name not in agent["inventory"]
+    assert obj["location"] == "room1"
+
+
+@pytest.mark.asyncio
+async def test_action_open_chest_with_key(world: MicroWorld) -> None:
+    """Test unlocking and opening a chest with a key."""
+    agent_name = "SymbolicAGI"
+    chest = world.get_object("Chest")
+    assert chest["state"] == "locked"
+
+    # Move to room1 (chest) and then room2 (key)
+    await world.perform_action("move", agent_name=agent_name, new_location="room2")
+    # Pick up the key
+    await world.perform_action("pickup", agent_name=agent_name, object_name="Key")
+    # Move back to the chest
+    await world.perform_action("move", agent_name=agent_name, new_location="room1")
+
+    agent = world.get_agent(agent_name)
+    assert "Key" in agent["inventory"]
+
+    # Open the chest
+    open_result = await world.perform_action("open", agent_name=agent_name, object_name="Chest")
+
+    assert open_result["status"] == "success"
+    assert "Unlocked the Chest" in open_result["description"]
+    assert chest["state"] == "unlocked"
+
+
+def test_state_persistence(tmp_path):
+    """Test that world state is saved and loaded correctly."""
+    state_file = tmp_path / "microworld_state.json"
+    with patch("micro_world.config.DATA_DIR", str(tmp_path)):
+        with patch("micro_world.config.STATE_FILE_PATH", str(state_file)):
+            world1 = MicroWorld()
+            world1.add_agent("Charlie", "room1")
+            world1._save_state(world1.state)
+
+            assert os.path.exists(state_file)
+
+            world2 = MicroWorld()
+            assert world2.get_agent("Charlie") is not None
+            assert world2.get_agent("Charlie")["location"] == "room1"
